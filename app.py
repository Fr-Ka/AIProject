# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z5ipod5488AeW4iLOEq0Y-CvhUbZ2H7a
"""

import streamlit as st
from transformers import GPT2LMHeadModel, GPT2Tokenizer
from PIL import Image
import requests
from io import BytesIO

st.title("AI-Powered Meme Generator")

st.sidebar.title("Meme Generator")
st.sidebar.markdown("Upload an image and provide context for your meme.")

uploaded_file = st.sidebar.file_uploader("Choose an image...", type="jpg")

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption='Uploaded Image.', use_column_width=True)

    context = st.sidebar.text_input("Enter the context or theme for the meme")

    if st.sidebar.button("Generate Meme"):
        st.write("Generating meme...")

        # Load the local GPT-2 model and tokenizer
        model_path = "gpt2_model"
        model = GPT2LMHeadModel.from_pretrained(model_path)
        tokenizer = GPT2Tokenizer.from_pretrained(model_path)

        if context:
            # Generate meme caption using the local GPT-2 model
            inputs = tokenizer.encode(context, return_tensors='pt')
            outputs = model.generate(inputs, max_length=50, num_return_sequences=1)
            meme_caption = tokenizer.decode(outputs[0], skip_special_tokens=True)

            st.write(f"Generated Meme Caption: {meme_caption}")
        else:
            st.write("Please provide context for the meme.")